{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK Flows\n",
    "\n",
    "This tutorial will explain the concept of `Flows`.\n",
    "Flows are used to bundle or chain a set of Tasks. E.g. Start a Training, perform a Test and run predictions on a dataset using an Inference Task.\n",
    "While Tasks are more low level building blocks that require more in depth configuration (gaining flexibility), Flows are high level and easier in use. If you often use the same chain of Tasks, you can make your own Flow to structure your code better.\n",
    "\n",
    "Flows are also used under the hood of the RVAI platform to run the whole training flow of a customer, or to perform k-fold validation.\n",
    "Additionally, flows are used for algorithm CI/CD, to have a quick and elegant way to test an algorithm fully end-to-end.\n",
    "## Installation\n",
    "\n",
    "First install the required the sdk python packages.\n",
    "Simplest way is to install the 'rvai' meta package which will install all SDK related packages. Access to our devpi server is required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq rvai==1.1.0rc51 pygraphviz rvai.pipelines.dummy_sdk_pipeline==1.1.0rc13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataset\n",
    "\n",
    "Because the definition of Cells and Pipelines is already covered in other tutorials, we use a dummy sdk pipeline for this one. Because the dummy pipeline does not really train, we create a dataset with random data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required RVAI base class\n",
    "from rvai.base.data import Dataset\n",
    "\n",
    "# used for typing\n",
    "from rvai.types import Image, BoundingBox, Point\n",
    "from typing import Sequence, Tuple\n",
    "import numpy as np\n",
    "\n",
    "from rvai.pipelines.dummy_sdk_pipeline.dummy_cells import DummySamples, DummyAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(\n",
    "    Dataset[DummySamples, DummyAnnotations]\n",
    "):\n",
    "    def __init__(\n",
    "        self, length: int\n",
    "    ):\n",
    "        # create random data\n",
    "        self.images = [Image(np.random.random((100, 50, 3))) for i in range(length)]\n",
    "        self.bounding_boxes = [BoundingBox(p1=Point(x=0, y=0), p2=Point(x=1, y=1)) for i in range(length)]\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index\n",
    "    ) -> Tuple[DummySamples, DummyAnnotations]:\n",
    "        return (\n",
    "            DummySamples(image=self.images[index]),\n",
    "            DummyAnnotations(bbox=self.bounding_boxes[index]),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "train_dataset = DummyDataset(80)\n",
    "validation_dataset = DummyDataset(10)\n",
    "test_dataset = DummyDataset(1)\n",
    "\n",
    "# display an example image and its label\n",
    "samples, annotations = train_dataset[0]\n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Evaluate - Test Flow\n",
    "The `TrainTestEvalFlow` executes a Training, a Test and additionally performs a prediction on each sample in the optional test_dataset. The results of all tasks are passed through via the `.updates()` method. In the RVAI platform, all prediction results are saved to the database to later visualize them in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rvai.base.runtime import init\n",
    "from rvai.base.inference import PredictionResult\n",
    "\n",
    "from rvai.base.flows import KFoldTrainTestEvalFlow, TrainTestEvalFlow\n",
    "from rvai.pipelines.dummy_sdk_pipeline.dummy_sdk_pipeline import DummySDKPipeline\n",
    "from rvai.pipelines.dummy_sdk_pipeline.dummy_cells import DummyTrainingParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = init('ray')\n",
    "\n",
    "# Get the training pipeline\n",
    "inference_pipeline = DummySDKPipeline.build()\n",
    "cell_ref, cell_base = inference_pipeline.trainable_cells[0]\n",
    "\n",
    "training_pipeline = inference_pipeline.get_training_pipeline(cell_base)\n",
    "trainable_cell_ref = training_pipeline.get_cell_ref(training_pipeline.trainable_cell)\n",
    "parameters = DummyTrainingParameters(epochs=5)\n",
    "\n",
    "# define the flow\n",
    "flow = TrainTestEvalFlow(\n",
    "        runtime=rt,\n",
    "        pipeline=training_pipeline,\n",
    "        models={},\n",
    "        parameters={trainable_cell_ref: parameters},\n",
    "        train_dataset=train_dataset,\n",
    "        validation_dataset=validation_dataset,\n",
    "        test_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Start the flow & follow up on updates\n",
    "flow.start()\n",
    "async for update in flow.updates():\n",
    "    print(update)\n",
    "\n",
    "# Finally get the result, containing metrics and model_path\n",
    "result = await flow\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation setup\n",
    "\n",
    "The k-fold cross validation is used for a very limited set of customers who want to validate their models on 100% of their data.\n",
    "So the k-fold cross validation flow, does k trainings, each time with $\\frac{1}{k}\\%$ of the data as testset and $1-\\frac{1}{k}\\%$ as train dataset.\n",
    "In this way, after $k$ times, the whole dataset has been in the testset once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the flow\n",
    "flow = KFoldTrainTestEvalFlow(\n",
    "        runtime=rt,\n",
    "        pipeline=training_pipeline,\n",
    "        models={},\n",
    "        parameters={trainable_cell_ref: parameters},\n",
    "        train_dataset=train_dataset,\n",
    "        validation_dataset=validation_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        folds=3,\n",
    ")\n",
    "\n",
    "# Start the flow & follow up on updates\n",
    "flow.start()\n",
    "async for update in flow.updates():\n",
    "    # filter so the output is not flood\n",
    "    if not isinstance(update, PredictionResult):\n",
    "        print(update)\n",
    "\n",
    "# Finally get the result, containing metrics and model_path\n",
    "result = await flow\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
